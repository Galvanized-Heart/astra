# General settings
seed: 42
project_name: "astra"

# Data configuration -- POINT TO YOUR HPO SPLITS
data:
  train_path: "data/hpo_splits/hpo_train.csv"
  valid_path: "data/hpo_splits/hpo_valid.csv"
  batch_size: 64 # This will be overwritten by the sweep
  featurizer_batch_size: 128
  target_columns: ["kcat", "KM", "Ki"]
  target_transform: "log10"

# Featurizers (fixed for this HPO run)
featurizers:
  protein:
    name: "ESMFeaturizer"
    params:
      model_name: "facebook/esm2_t6_8M_UR50D" # Use a smaller model for faster HPO
      max_length: 1022
  ligand:
    name: "MorganFeaturizer"
    params:
      radius: 2
      fp_size: 2048

# Model configuration -- these values are placeholders
model:
  architecture:
    name: "CpiPredConvModel"
    params: 
      hid_dim: 128
      kernal_1: 9
      conv_out_dim: 64
      kernal_2: 5
      last_hid: 256
      dropout: 0.1
  
  lightning_module:
    lr: 0.001
    optimizer: "AdamW"
    loss_function: "MaskedMSELoss"
    lr_scheduler:
      name: "ReduceLROnPlateau"
      params:
        monitor: "valid_loss_epoch"
        mode: "min"
        factor: 0.1
        patience: 3

# Trainer configuration
trainer:
  epochs: 20 # A reasonable number of epochs for HPO runs
  device: "auto"
  callbacks:
    checkpoint:
      monitor: "valid_loss_epoch"
      save_top_k: 1
      mode: "min"